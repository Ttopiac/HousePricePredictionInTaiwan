{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A top 1% Model for 2019 Esun AI Competition: Taiwan House Price Prediction\n",
    "## This is an ensemble learning model, composed with a base model and a model, modified based on the city feature\n",
    "## In this file, the base model will be explained briefly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import norm, skew #for some statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions, which will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop outliers\n",
    "# outliers: house with incredible huge building area\n",
    "def DropIndexs(dataset):\n",
    "    all_data = dataset.copy()\n",
    "    all_data = all_data.drop(all_data[(all_data['building_area']>80)].index)\n",
    "    return all_data\n",
    "\n",
    "# Log-normal transformation on the hosue price feature\n",
    "def PreProcessingForOnlyTr(dataset):\n",
    "    all_data = dataset.copy()\n",
    "    all_data[\"total_price\"]=all_data['total_price']/all_data['building_area']\n",
    "    all_data[\"total_price\"] = np.log1p(all_data[\"total_price\"])\n",
    "    return all_data  \n",
    "\n",
    "# data preprocessing, \n",
    "# including creating hidden features, filling missing values, \n",
    "# dropping bad features and some other feature engineering.\n",
    "def PreProcessing(dataset):\n",
    "    all_data = dataset.copy()\n",
    "    ## Variable Transformation\n",
    "    ## Predict price per sq\n",
    "    ## Log Trasnformation\n",
    "    all_data[\"building_area\"] = np.log1p(all_data[\"building_area\"])\n",
    "    all_data[\"land_area\"] = np.log1p(all_data[\"land_area\"])\n",
    "    ### Feature Engineering\n",
    "    all_data['N_500']=all_data['N_500']-all_data['N_50']\n",
    "    all_data['N_1000']=all_data['N_1000']-all_data['N_500']-all_data['N_50']\n",
    "    all_data['N_5000']=all_data['N_5000']-all_data['N_1000']-all_data['N_500']-all_data['N_50']\n",
    "    all_data['N_10000']=all_data['N_10000']-all_data['N_5000']-all_data['N_1000']-all_data['N_500']-all_data['N_50']\n",
    "    # # Filling missing values\n",
    "    all_data['txn_floor']=all_data['txn_floor'].fillna(0)\n",
    "    all_data['parking_price']=all_data['parking_price'].fillna(0)\n",
    "    all_data['parking_area']=all_data['parking_area'].fillna(0)\n",
    "    all_data[\"parking_area\"] = np.log1p(all_data[\"parking_area\"])\n",
    "    all_data['village_income_median']=all_data['village_income_median'].fillna(0)\n",
    "    # # Create hidden features\n",
    "    all_data['roof']=np.where(all_data['total_floor']==all_data['txn_floor'], 0, 1)\n",
    "    all_data['house_age']=all_data['txn_dt']-all_data['building_complete_dt']\n",
    "    all_data['material_price']=pd.np.where((all_data['building_material']==10)|(all_data['building_material']==9)|(all_data['building_material']==5), 0, 1)\n",
    "    all_data['building_material'] = all_data['building_material'].apply(str)\n",
    "    all_data['building_type'] = all_data['building_use'].apply(str)\n",
    "    all_data['building_use'] = all_data['building_type'].apply(str)\n",
    "    all_data['town'] = all_data['town'].apply(str)\n",
    "    all_data['year']=(all_data['building_complete_dt']/365).apply(str)\n",
    "    all_data['parking_way'] = all_data['parking_way'].apply(str)\n",
    "    all_data['txn_floor'] = all_data['txn_floor'].apply(str)\n",
    "    all_data['village']=all_data['village'].apply(str)\n",
    "    all_data['lon']=all_data['lon'].apply(str)\n",
    "    ########################################## Transform skewness\n",
    "    numeric_feats = all_data.dtypes[(all_data.dtypes != \"object\" ) & (all_data.columns != \"city\")].index\n",
    "    # # Check the skew of all numerical features\n",
    "    skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\n",
    "    skewness = pd.DataFrame({'Skew' :skewed_feats})\n",
    "    skewness = skewness.head(10)\n",
    "    skewness = skewness[abs(skewness) > 0.55]\n",
    "    skewed_features = skewness.index\n",
    "    lam = 0.6\n",
    "    for feat in skewed_features:\n",
    "        #all_data[feat] += 1\n",
    "        all_data[feat] = boxcox1p(all_data[feat], lam)\n",
    "    all_data=pd.get_dummies(all_data, columns=['txn_floor','lon','roof','year','town','building_material','building_use','building_type','village','material_price','parking_way'])\n",
    "    # ## drop Variable\n",
    "    all_data.drop(\"lat\", axis = 1, inplace = True)\n",
    "    all_data.drop(\"born_rate\", axis = 1, inplace = True)\n",
    "    all_data.drop(\"death_rate\", axis = 1, inplace = True)\n",
    "    all_data.drop(\"marriage_rate\", axis = 1, inplace = True)\n",
    "    all_data.drop(\"divorce_rate\", axis = 1, inplace = True)\n",
    "    return all_data\n",
    "\n",
    "# Post Processing\n",
    "def PostProcessingForThePrice(dataset, priceList):\n",
    "    priceList = np.expm1(priceList)\n",
    "    priceList = priceList*dataset['building_area'].values\n",
    "    # brutal force especially on high price data\n",
    "    q2 = np.quantile(priceList, .996)\n",
    "    priceList = np.where(priceList < q2, priceList, priceList * 1.2 )\n",
    "    return priceList\n",
    "\n",
    "# Align a dataset with another dataset\n",
    "# After this process,  oridata will be added columns(features), \n",
    "# which was not existed in it, but existed in the target data.  \n",
    "def GetMissingColumns( oriData, target):\n",
    "    # Get missing columns in the training test\n",
    "    missing_cols = set( target.columns ) - set( oriData.columns )\n",
    "    # Add a missing column in test set with default value equal to 0\n",
    "    for c in missing_cols:\n",
    "        if c is not \"total_price\":\n",
    "            oriData[c] = 0\n",
    "    # Ensure the order of column in the test set is in the same order than in train set\n",
    "    oriData = oriData[target.columns]\n",
    "    return oriData\n",
    "\n",
    "# Train the model with the trainset\n",
    "def Model_Wholedataset(trainset, models):\n",
    "    trainForBigModel = trainset.copy()\n",
    "    y = trainForBigModel[\"total_price\"].values\n",
    "    trainForBigModel.drop(['building_id', 'total_price'], inplace=True, axis=1)\n",
    "    x = trainForBigModel.values\n",
    "    model = lightgbm.LGBMRegressor(objective='regression',num_leaves=125,\n",
    "                                  learning_rate=0.012, n_estimators=61002,\n",
    "                                  max_bin = 1550, bagging_fraction = 0.8,\n",
    "                                  bagging_freq = 5, feature_fraction = 0.3319,\n",
    "                                  feature_fraction_seed=9, bagging_seed=9,\n",
    "                                  min_data_in_leaf =10, min_sum_hessian_in_leaf = 16)\n",
    "    model.fit(x,y)\n",
    "    models.update({'bigModel': model})\n",
    "    return models\n",
    "\n",
    "# Get the prediction house price of testset by the trained model\n",
    "def Get_predict_of_theModel(originTest, afPreprocTest, model):\n",
    "    dataset = afPreprocTest.copy()\n",
    "    dataset.drop(['building_id', 'total_price'], inplace=True, axis=1)\n",
    "    x = dataset.values\n",
    "    y = model.predict(x)\n",
    "    predictByModel = PostProcessingForThePrice(originTest, y)    \n",
    "    return predictByModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data\n",
    "#### 1. read the file\n",
    "#### 2. drop the outliers\n",
    "#### 3. data preprocessing, including creating hidden features, filling missing values, dropping bad features and some other feature engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission_data size is : (10000, 4211)\n",
      "train_data size is : (47820, 4211)\n"
     ]
    }
   ],
   "source": [
    "train_csv = pd.read_csv('train.csv')\n",
    "trainBefPreproc, valBefPreproc = train_test_split(train_csv, test_size=0.2, random_state=42)\n",
    "\n",
    "trainAfDrop = DropIndexs(trainBefPreproc)\n",
    "train = PreProcessingForOnlyTr(trainAfDrop)\n",
    "train = PreProcessing(train)\n",
    "    \n",
    "valAfDrop = DropIndexs(valBefPreproc)\n",
    "val = PreProcessingForOnlyTr(valAfDrop)\n",
    "val = PreProcessing(val)\n",
    "\n",
    "submissionBefPreproc = pd.read_csv('test.csv')\n",
    "submission = PreProcessing(submissionBefPreproc)\n",
    "\n",
    "if(len(train.columns)>=len(submission.columns)):\n",
    "    submission = GetMissingColumns(submission, train)\n",
    "    print(\"submission_data size is : {}\".format(submission.shape))    \n",
    "    train = GetMissingColumns(train, submission)\n",
    "    print(\"train_data size is : {}\".format(train.shape))\n",
    "else:\n",
    "    train = GetMissingColumns(train, submission)\n",
    "    print(\"train_data size is : {}\".format(train.shape))\n",
    "    submission = GetMissingColumns(submission, train)\n",
    "    print(\"submission_data size is : {}\".format(submission.shape))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelDict = {}\n",
    "modelDict = Model_Wholedataset(train, modelDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the hosuing price accodding to the testset by the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictBybigModel = Get_predict_of_theModel(submissionBefPreproc, submission, modelDict[\"bigModel\"])\n",
    "ids = submission['building_id'].values\n",
    "output = pd.DataFrame({'building_id': ids, 'total_price': predictBybigModel})\n",
    "output.to_csv(\"submissionBybigModel.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
